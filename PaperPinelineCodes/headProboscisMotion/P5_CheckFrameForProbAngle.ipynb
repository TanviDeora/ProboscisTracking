{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs(vidPath, firstFrame, lastFrame):\n",
    "    '''\n",
    "    Reads frames from video and stores as a list\n",
    "    \n",
    "    Parameters: \n",
    "    vidPath (string): Path to video\n",
    "    \n",
    "    Returns: \n",
    "    list of images\n",
    "    '''\n",
    "    \n",
    "    cap = cv2.VideoCapture(vidPath)\n",
    "    length = np.arange(firstFrame, lastFrame)\n",
    "    print(len(length)) \n",
    "    imgs = []\n",
    "    for ff in length:\n",
    "        cap.set(1,ff)\n",
    "        ret, frame = cap.read()\n",
    "        if np.mod(ff, 100) == 0:\n",
    "            print(ff) # prints progress in 50 frames\n",
    "\n",
    "            # convert to grey\n",
    "            #img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        imgs.append(frame)\n",
    "#         print(\"length of imgs: %s\" % len(imgs))\n",
    "            \n",
    "    cap.release()\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust gamma, if your vid is too dark\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    " \n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first = ['c-1_m13', 'c-2_m20','c-3_m10', 'c-10_m11']\n",
    "first = ['c-10_m20']\n",
    "direc = r'./dataFolders/PaperPipelineOutput/v3/OtherBodyParts/FirstVisit/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the list of final proboscis tracks as starting point to get the corresponding head and thorax data\n",
    "visitnum = 0\n",
    "path_for_visit_frames = r\"../MothLearning/dataFolders/Output/Step5_FilesWith_TrueTrialAnd_ProboscisDetect_v2/\"\n",
    "\n",
    "#get path for videos\n",
    "pathForVideo = r\"G:\\My Drive\\Tom-Tanvi\\Moth Learning Project\\AllVideosForAnalysis\\CompliedDataForAnalysis\"\n",
    "ourVideoPath = glob.glob(pathForVideo + \"\\**\\\\*.mp4\", recursive = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category = ['acute', 'obtuse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711\n",
      "48100\n",
      "48200\n",
      "48300\n",
      "48400\n",
      "48500\n",
      "48600\n",
      "48700\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for mothID in first[0:1]:\n",
    "    if not os.path.exists(direc + mothID + '_probHeadAngle.csv'):\n",
    "        mothID = mothID + '_cropped'\n",
    "    df = pd.read_csv(direc + mothID + '_ProbHeadAntennae.csv')\n",
    "    df_angle = pd.read_csv(direc + mothID + '_probHeadAngle.csv')\n",
    "\n",
    "#     proboscis = pd.read_csv(direc + mothID + '_proboscis_notCentered.csv')\n",
    "#     headJoint = pd.read_csv(direc + mothID + '_HeadprobJoint_notCentered.csv')\n",
    "#     mothCenter = pd.read_csv(direc + mothID + '_MothCOM_notCentered.csv')\n",
    "    \n",
    "    LfAntennae = df.loc[:, 'LAnt_x' : 'LAnt_y']\n",
    "    RtAntennae = df.loc[:, 'RAnt_x': 'RAnt_y']\n",
    "    head_dir = df.loc[:, 'head_dir_x':'head_dir_y']\n",
    "    head = df.loc[:, 'head_x':'head_y']\n",
    "    proboscis = df.loc[:, 'probocis_x':'probocis_y']\n",
    "\n",
    "    tracks = [LfAntennae, RtAntennae, head_dir, head, proboscis]\n",
    "    for tt in tracks:\n",
    "        tt.columns = ['x', 'y']    \n",
    "    \n",
    "    path_frame_Reference = glob.glob(path_for_visit_frames + mothID + '_RawDataForExplorationTime.csv')\n",
    "    Visit_info_f = pd.read_csv(path_frame_Reference[0])\n",
    "    Visit_info = Visit_info_f[['MothIN', 'MothOut','ProboscisDetect']]\n",
    "\n",
    "    fin = Visit_info.iloc[visitnum, 0]\n",
    "    fout = Visit_info.iloc[visitnum, 2]\n",
    "    if np.isnan(fout):\n",
    "        fout = Visit_info.iloc[visitnum, 1]\n",
    "\n",
    "    fin = int(fin)\n",
    "    fout = int(fout)\n",
    "\n",
    "    SpecificVideoPath = [f for f in ourVideoPath if mothID + '.mp4' in f][0]\n",
    "    # load images\n",
    "    imList = load_imgs(SpecificVideoPath, fin, fout)\n",
    "    \n",
    "#     for cat in category:\n",
    "        \n",
    "#         if cat == 'obtuse':\n",
    "#             subset = df[(df.ProbAngle > np.pi/2) | (df.ProbAngle < -np.pi/2)]\n",
    "#         else:\n",
    "#             subset = df[(df.ProbAngle < np.pi/2) | (df.ProbAngle > -np.pi/2)]\n",
    "#         len(df), len(subset)\n",
    "   \n",
    "    # make directory to store images\n",
    "    string = mothID + '_checkHeadDirection'\n",
    "    tempImgDirectory = os.path.join(os.path.dirname(r\"./dataFolders/PaperPipelineOutput/Figures/v3/OtherBodyPartTracks/VideoCheck/temp/\"), string)\n",
    "    if not os.path.exists(tempImgDirectory):\n",
    "        os.mkdir(tempImgDirectory)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    for idx in df.index:\n",
    "        # adjust gamma\n",
    "        image = adjust_gamma(imList[idx], 1.5)\n",
    "        plt.imshow(image)\n",
    "\n",
    "        prob = proboscis.x[idx], proboscis.y[idx]\n",
    "        hJ = head.x[idx], head.y[idx]\n",
    "        hdir = head_dir.x[idx], head_dir.y[idx]\n",
    "\n",
    "        hJ2prob_x_values = [hJ[0], prob[0]]\n",
    "        hJ2prob_y_values = [hJ[1], prob[1]]\n",
    "        plt.plot(hJ2prob_x_values, hJ2prob_y_values, 'm')\n",
    "\n",
    "        body_x_values = [hJ[0], hdir[0]]\n",
    "        body_y_values = [hJ[1], hdir[1]]\n",
    "        plt.plot(body_x_values, body_y_values, 'y')\n",
    "\n",
    "        plt.plot(hJ[0], hJ[1], 'o', color = 'orange')\n",
    "        plt.plot(hdir[0], hdir[1], 'o', color = 'green')\n",
    "\n",
    "        aa = df_angle.ProbAngle[idx]*180/np.pi\n",
    "\n",
    "        s = 'angle = %0.3f' %aa\n",
    "    #     s = 'test'\n",
    "        plt.text(400, 50, s, fontsize=12, c = 'white')\n",
    "\n",
    "        plt.savefig(tempImgDirectory + '/' + str(idx).zfill(4) + '.png')\n",
    "        plt.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
