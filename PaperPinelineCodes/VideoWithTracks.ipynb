{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open cv2 version: 3.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "print(\"open cv2 version: %s\" % cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs(vidPath, firstFrame, lastFrame):\n",
    "    '''\n",
    "    Reads frames from video and stores as a list\n",
    "    \n",
    "    Parameters: \n",
    "    vidPath (string): Path to video\n",
    "    \n",
    "    Returns: \n",
    "    list of images\n",
    "    '''\n",
    "    \n",
    "    cap = cv2.VideoCapture(vidPath)\n",
    "    length = np.arange(start, stop)\n",
    "    print(len(length))\n",
    "    imgs = []\n",
    "    for ff in length:\n",
    "        cap.set(1,ff)\n",
    "        ret, frame = cap.read()\n",
    "        if np.mod(ff, 100) == 0:\n",
    "            print(ff) # prints progress in 50 frames\n",
    "\n",
    "            # convert to grey\n",
    "            #img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        imgs.append(frame)\n",
    "#         print(\"length of imgs: %s\" % len(imgs))\n",
    "            \n",
    "    cap.release()\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust gamma, if your vid is too dark\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    " \n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     names AutomatatedTracking\n",
      "0           0  c-10_m10                TRUE\n",
      "1           1  c-10_m11                TRUE\n",
      "2           2  c-10_m12         VIDEO check\n",
      "3           3  c-10_m13         VIDEO check\n",
      "4           4  c-10_m15         VIDEO check\n"
     ]
    }
   ],
   "source": [
    "# list of mothIDs that require video making\n",
    "\n",
    "guide = pd.read_csv(\"../dataFolders/PaperPipelineOutput/FilteredTracks_v2/FirstVisit/AllVideoNames.csv\")\n",
    "print(guide.head())\n",
    "filesToRead = guide[guide.AutomatatedTracking != \"TRUE\"]\n",
    "\n",
    "pathForVideo = r\"G:\\My Drive\\Tom-Tanvi\\Moth Learning Project\\AllVideosForAnalysis\\CompliedDataForAnalysis\"\n",
    "\n",
    "ourVideoPath = glob.glob(pathForVideo + \"\\**\\\\*.mp4\", recursive = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the tracks\n",
    "\n",
    "direc = r\"../dataFolders/PaperPipelineOutput/FilteredTracks_v2/ManualCleanup/FinalTracks/FirstVisit/\"\n",
    "AllTracks = glob.glob(direc + \"*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use step 5 in moth learning to read out all the start stop frame numbers\n",
    "\n",
    "path_for_visit_frames = r\"../../MothLearning/dataFolders/Output/Step5_FilesWith_TrueTrialAnd_ProboscisDetect_v2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183794 648 488 30.0\n",
      "1088\n",
      "20300.0\n",
      "20400.0\n",
      "20500.0\n",
      "20600.0\n",
      "20700.0\n",
      "20800.0\n",
      "20900.0\n",
      "21000.0\n",
      "21100.0\n",
      "21200.0\n",
      "21300.0\n",
      "length of section you want to read: 1088\n",
      "length of the image list: 1088\n",
      "length of track is: 879\n",
      "0  of  879\n",
      "100  of  879\n",
      "200  of  879\n",
      "300  of  879\n",
      "400  of  879\n",
      "500  of  879\n",
      "600  of  879\n",
      "700  of  879\n",
      "800  of  879\n",
      "../dataFolders/PaperPipelineOutput/Figures/v2/Videos\\tmpImgs\n"
     ]
    }
   ],
   "source": [
    "# open the video and create an image stack of relevant frames\n",
    "for mothID in filesToRead.names.values[0:1]:\n",
    "\n",
    "    mothID = 'c-3_m10'\n",
    "# mothID = filesToRead.names.values[0]\n",
    "# mothID = 'c-1_m13'\n",
    "    SpecificVideoPath = [f for f in ourVideoPath if mothID in f][0]\n",
    "\n",
    "    if not os.path.isfile(SpecificVideoPath): print(\"video doesn not exist\")\n",
    "\n",
    "\n",
    "    path_frame_Reference = glob.glob(path_for_visit_frames + mothID + '*RawDataForExplorationTime.csv')\n",
    "    Visit_info = pd.read_csv(path_frame_Reference[0])\n",
    "    Visit_info = Visit_info[['MothIN', 'MothOut','ProboscisDetect']]\n",
    "\n",
    "    visit_num = 0\n",
    "    start = Visit_info.loc[visit_num, 'MothIN']\n",
    "    stop = Visit_info.loc[visit_num, 'ProboscisDetect']\n",
    "    if np.isnan(stop):\n",
    "        stop = Visit_info.loc[visit_num, 'MothOut']\n",
    "\n",
    "\n",
    "    # get the list of images\n",
    "\n",
    "    # get vid info\n",
    "    cap = cv2.VideoCapture(SpecificVideoPath)\n",
    "\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    print(length, width, height, fps)\n",
    "    cap.release()\n",
    "\n",
    "    # load images\n",
    "    imList = load_imgs(SpecificVideoPath, start, stop)\n",
    "\n",
    "    print(\"length of section you want to read: %s\" % int(stop - start))\n",
    "    print(\"length of the image list: %s\" % len(imList))\n",
    "    \n",
    "    # get the track for that mothID\n",
    "    specificTrack = [f for f in AllTracks if mothID in f][0]\n",
    "    track = pd.read_csv(specificTrack)\n",
    "    x = track.x.values\n",
    "    y = track.y.values\n",
    "\n",
    "    print('length of track is: ' + str(len(x)))\n",
    "    \n",
    "    # trancate the image list to track length\n",
    "    imList = imList[:len(x)]\n",
    "    \n",
    "    \n",
    "    # # make directory to store images\n",
    "    tempImgDirectory = os.path.join(os.path.dirname(r\"../dataFolders/PaperPipelineOutput/Figures/v2/Videos/\"), \"tmpImgs\")\n",
    "    if not os.path.exists(tempImgDirectory):\n",
    "        os.mkdir(tempImgDirectory)\n",
    "\n",
    "    # add circles up to XX points in the past\n",
    "\n",
    "    lagPoints = 50 # number of points to plot on each frame\n",
    "    alphaVals = np.flip(np.linspace(0, 0.2, lagPoints), axis = 0)\n",
    "    vidLen = len(imList)\n",
    "    total_zoom = 500\n",
    "\n",
    "    outputImgs = []\n",
    "    for frameNum in np.arange(0, vidLen):\n",
    "\n",
    "        # adjust gamma\n",
    "        image = adjust_gamma(imList[frameNum], 1.5)\n",
    "\n",
    "        # convert to rgb, so I can add colored points\n",
    "        #image = cv2.cvtColor(im1,cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        overlay = image.copy()\n",
    "        output = image.copy()\n",
    "        for jj in range(lagPoints):\n",
    "            if np.isnan(x[np.max([frameNum-jj, 0])]) or np.isnan(y[np.max([frameNum-jj, 0])]) :\n",
    "                continue                                          \n",
    "                                                \n",
    "            # add circle, centered at closest integer value\n",
    "            cv2.circle(overlay, (int(x[np.max([frameNum-jj, 0])]), \n",
    "                                 int(y[np.max([frameNum-jj, 0])])), \n",
    "                       3, (219, 189, 166), -1)\n",
    "            cv2.addWeighted(overlay, alphaVals[jj], output, 1 - alphaVals[jj],0, output)\n",
    "\n",
    "        f = plt.figure(figsize = (8, 3))\n",
    "        ax0 = f.add_subplot(121)\n",
    "        ax1 = f.add_subplot(122)\n",
    "\n",
    "        ax0.imshow(output)\n",
    "        ax0.set_xticks([])\n",
    "        ax0.set_yticks([])\n",
    "\n",
    "        if len(track) < total_zoom:\n",
    "            (zoom_in_str, zoom_in_stop) = (0,vidLen)\n",
    "        else:\n",
    "            if frameNum > 20:\n",
    "                (zoom_in_str, zoom_in_stop) = (frameNum - 20, frameNum + total_zoom - 20)\n",
    "                if frameNum + total_zoom > vidLen:\n",
    "                    (zoom_in_str, zoom_in_stop) = (vidLen-total_zoom,vidLen)\n",
    "            else:\n",
    "                (zoom_in_str, zoom_in_stop) = (frameNum,frameNum+total_zoom)\n",
    "\n",
    "        x_range = np.arange(zoom_in_str, zoom_in_stop)*1/100\n",
    "        ax1.plot(x_range, track.r[zoom_in_str:zoom_in_stop], 'k')\n",
    "        ax1.plot(frameNum*1/100, track.r[frameNum], 'ob')\n",
    "        ax1.set_ylim(0,5)\n",
    "        ax1.set_xlabel('Time (sec)')\n",
    "        ax1.set_ylabel('Radial Distance')\n",
    "\n",
    "        plt.tight_layout(pad=0.1, h_pad=None, w_pad=0.5, rect=None)\n",
    "\n",
    "    # use GridSpec for controlling the spacing of the subplots\n",
    "\n",
    "        # display image -- it may be a bit faster if you don't display the images\n",
    "    #     cv2.imshow(output) \n",
    "\n",
    "    #     save img\n",
    "        plt.savefig(os.path.join(tempImgDirectory, str(frameNum).zfill(4) + \".png\"))\n",
    "        plt.close()\n",
    "\n",
    "        if np.mod(frameNum, 100) == 0:\n",
    "            print(frameNum, \" of \", vidLen)\n",
    "            \n",
    "    # convert images to video with ffmpeg\n",
    "    os.chdir(tempImgDirectory)\n",
    "    print(tempImgDirectory)\n",
    "\n",
    "    # use ffmpeg to convert directory to video\n",
    "    # -r is output frame rate\n",
    "    os.system('ffmpeg -start_number 0 -r 20 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264 -pix_fmt yuv420p -y outputVid.mp4')\n",
    "    nameofVideo = r'./' + mothID    + '.mp4'\n",
    "    os.rename(r'./outputVid.mp4', nameofVideo)\n",
    "    os.chdir('../../../../../../PaperPinelineCodes/')\n",
    "\n",
    "    # delete images from directory\n",
    "    delFiles = [f for f in os.listdir(tempImgDirectory) if f.endswith(\"png\")]\n",
    "\n",
    "    dlfs = [os.remove(os.path.join(tempImgDirectory, delFiles[ii])) for ii in range(len(delFiles))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
